{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU0wD0LEBbVZ"
   },
   "source": [
    "# Lab 01: Language Modeling with Transformers - Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93458,
     "status": "ok",
     "timestamp": 1634567655909,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "qoogmpRzBbVg",
    "outputId": "35869086-1838-44ec-88de-fa0d70986096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "/content/gdrive/My Drive/CS5242_notebooks/labs_lecture12/lab01_language_model/\n",
      "/content/gdrive/My Drive/CS5242_notebooks/labs_lecture12/lab01_language_model\n"
     ]
    }
   ],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    # find automatically the path of the folder containing \"file_name\" :\n",
    "    file_name = 'transformer_language_modeling.ipynb'\n",
    "    import subprocess\n",
    "    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n",
    "    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n",
    "    # if previous search failed or too long, comment the previous line and simply write down manually the path below :\n",
    "    #path_to_file = '/content/gdrive/My Drive/CS5242_2021_codes/codes/labs_lecture12/lab01_language_model/'\n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"file_name\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 13890,
     "status": "ok",
     "timestamp": 1634567669793,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "A3yiLJBBBbVh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import time\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pe01LtUIBbVj"
   },
   "source": [
    "### GPU\n",
    "\n",
    "It is recommended to run this code on GPU:<br> \n",
    "* Time for 1 epoch on GPU : 48 sec w/ Google Colab Tesla P100-PCIE-16GB <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1634567669794,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "g_A4HBT3BbVj",
    "outputId": "7144dbbd-e456-4701-e69d-ddb0ea90f0e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cuda available with GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "device= torch.device(\"cuda\")\n",
    "#device= torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda available with GPU:',torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6S3W2p84BbVk"
   },
   "source": [
    "### Download Penn Tree Bank\n",
    "\n",
    "The tensor train_data consists of 20 columns of 46,479 words.<br>\n",
    "The tensor test_data consists of 20 columns of 4,121 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2197,
     "status": "ok",
     "timestamp": 1634567671985,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "TnE-JNp_BbVk",
    "outputId": "bc93f6d2-e25f-4761-94bd-17ce6d6c6de2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46479, 20])\n",
      "torch.Size([4121, 20])\n"
     ]
    }
   ],
   "source": [
    "from utils import check_ptb_dataset_exists\n",
    "data_path=check_ptb_dataset_exists()\n",
    "\n",
    "train_data  =  torch.load(data_path+'ptb/train_data.pt')\n",
    "test_data   =  torch.load(data_path+'ptb/test_data.pt')\n",
    "\n",
    "print(  train_data.size()  )\n",
    "print(  test_data.size()   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDxTJimKBbVl"
   },
   "source": [
    "### Some constants associated with the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1634567671986,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "MS9EUUvbBbVm"
   },
   "outputs": [],
   "source": [
    "bs = 20\n",
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U9UvE28BbVm"
   },
   "source": [
    "### Make an attention net class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1634567671988,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "RRmg_OUaBbVn"
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_positional_encoding(seq_length, dim):\n",
    "    assert dim == 2* (dim//2) # check if dim is divisible by 2\n",
    "    pe = torch.zeros(seq_length, dim)\n",
    "    position = torch.arange(0, seq_length, dtype=torch.float).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / dim))\n",
    "    pe[:,0::2] = torch.sin(position * div_term)\n",
    "    pe[:,1::2] = torch.cos(position * div_term)\n",
    "    return pe        \n",
    "        \n",
    "    \n",
    "class Transformer_decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, nb_heads):\n",
    "        super(Transformer_decoder, self).__init__()\n",
    "        assert hidden_size == nb_heads* (hidden_size//nb_heads) # check if hidden_size is divisible by nb_heads\n",
    "        self.MHA = nn.MultiheadAttention(hidden_size, nb_heads)\n",
    "        self.LLcat = nn.Linear(2*hidden_size, hidden_size)\n",
    "        self.LL1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.LL2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.LN1 = nn.LayerNorm(hidden_size)\n",
    "        self.LN2 = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "    def forward(self, g_seq , pos):  \n",
    "        seq_length = g_seq.size(0)\n",
    "        bs = g_seq.size(1)\n",
    "        pos = pos.unsqueeze(dim=1).repeat_interleave(bs,dim=1) # size=(seq_length, bs, hidden_dim) \n",
    "        h_cat = self.LLcat(torch.cat( (g_seq, pos), dim=2 )) # size=(seq_length, bs, hidden_dim) \n",
    "        mask_visited_nodes = torch.ones(1, seq_length, device=g_seq.device).bool() # True=no_attention # size=(1, seq_length) \n",
    "        mask_visited_nodes[0,:seq_length//2] = False # allow attention to words from index 0 to seq_length/2\n",
    "        h_seq = []\n",
    "        h_MHA_seq = []\n",
    "        for t in range(seq_length//2, seq_length): \n",
    "            query = h_cat[t].unsqueeze(0) # size=(1, bs, hidden_dim) \n",
    "            mask_visited_nodes = mask_visited_nodes.clone()\n",
    "            mask_visited_nodes[0,t] = False # allow attention to current word indexed by t\n",
    "            mask_visited_nodes[0,t-seq_length//2] = True # prevent attention to the (past) word indexed by t-seq_length/2\n",
    "            h_MHA, _ = self.MHA(query, h_cat, h_cat, attn_mask=mask_visited_nodes) # size=(1, bs, hidden_dim)\n",
    "            h_MHA_seq.append(h_MHA)\n",
    "            h_seq.append(query)\n",
    "        h_MHA_seq = torch.stack(h_MHA_seq).squeeze()\n",
    "        h_seq = torch.stack(h_seq).squeeze() # size=(seq_length, bs, hidden_dim)  \n",
    "        h = self.LN1( h_seq + h_MHA_seq ) # size=(1, bs, hidden_dim)\n",
    "        h_MLP = self.LL2(torch.relu(self.LL1(h))) # size=(1, bs, hidden_dim) \n",
    "        h_seq = self.LN2( h + h_MLP ) # size=(1, bs, hidden_dim) \n",
    "        return h_seq\n",
    "    \n",
    "    \n",
    "class ANN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, nb_heads):\n",
    "        super(ANN, self).__init__()\n",
    "        self.decoder = Transformer_decoder(hidden_size, nb_heads)\n",
    "    \n",
    "    def forward(self, g_seq , pos ):\n",
    "        h_dec_seq = self.decoder( g_seq , pos )\n",
    "        return h_dec_seq \n",
    "    \n",
    "\n",
    "class attention_net(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, nb_heads):\n",
    "        super(attention_net, self).__init__()  \n",
    "        self.layer1 = nn.Embedding( vocab_size  , hidden_size  )\n",
    "        self.layer2 = ANN(hidden_size, nb_heads)\n",
    "        self.layer3 = nn.Linear(    hidden_size , vocab_size   )\n",
    "\n",
    "    def forward(self, word_seq, pos ):\n",
    "        g_seq     =   self.layer1( word_seq ) # size=(seq_length, bs, hidden_dim) \n",
    "        h_seq     =   self.layer2( g_seq , pos ) # size=(seq_length, bs, hidden_dim) \n",
    "        score_seq =   self.layer3( h_seq ) # size=(seq_length, bs, vocab_size)\n",
    "        return score_seq \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4FH3SgyBbVt"
   },
   "source": [
    "### Function to evaluate the network on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1634567671989,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "wcOReFN0IHcP"
   },
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    running_loss=0\n",
    "    num_batches=0    \n",
    "       \n",
    "    for count in range( 0 , 4120-seq_length ,  seq_length//2) :\n",
    "               \n",
    "        minibatch_data =  test_data[ count   : count+seq_length   ]\n",
    "        minibatch_label = test_data[ count+1 : count+seq_length+1 ]\n",
    "        pos = generate_positional_encoding(seq_length, hidden_size)\n",
    "        \n",
    "        minibatch_data = minibatch_data.to(device)\n",
    "        minibatch_label = minibatch_label.to(device)\n",
    "        pos = pos.to(device)\n",
    "\n",
    "        scores = net( minibatch_data, pos )\n",
    "        \n",
    "        scores = scores[-seq_length//2:,:,:]\n",
    "        minibatch_label = minibatch_label[-seq_length//2:,:]\n",
    "\n",
    "        minibatch_label = minibatch_label.view(  bs*seq_length//2 ) \n",
    "        scores = scores.view(  bs*seq_length//2 , vocab_size)\n",
    "        \n",
    "        loss = criterion(scores, minibatch_label) \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1        \n",
    "    \n",
    "    total_loss = running_loss/num_batches \n",
    "    print('test: exp(loss) = ', math.exp(total_loss)  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gnTKxy9BbVr"
   },
   "source": [
    "### Build the net. Choose the hidden size to be 128 and the number of heads to be 16. \n",
    "### How many parameters in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1634567671989,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "ADOYeTS6_SLO",
    "outputId": "1283bbd3-e46b-462e-f692-9273e5b0c45a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_net(\n",
      "  (layer1): Embedding(10000, 128)\n",
      "  (layer2): ANN(\n",
      "    (decoder): Transformer_decoder(\n",
      "      (MHA): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (LLcat): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (LL1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (LL2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (LN1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (LN2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Linear(in_features=128, out_features=10000, bias=True)\n",
      ")\n",
      "There are 2702480 (2.70 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128 \n",
    "nb_heads = 16\n",
    "\n",
    "net = attention_net(hidden_size, nb_heads)\n",
    "print(net)\n",
    "utils.display_num_param(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khaDFxmwBbVr"
   },
   "source": [
    "### Send the network to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 9482,
     "status": "ok",
     "timestamp": 1634567681462,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "Sp63FT_v_SLQ"
   },
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eecX1xVaBbVs"
   },
   "source": [
    "### Choose the loss to be the cross-entropy and the optimizer to be Adam, as well as the following important hyperparameters: \n",
    "* initial learning rate = 0.001\n",
    "* sequence length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1634567681465,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "LBm4Aw_j_SLR"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "my_lr = 0.001\n",
    "seq_length = 30\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=my_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frtpNDBLBbVs"
   },
   "source": [
    "### Do 10 passes through the training set\n",
    "### Observe the train perplexity and the test perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 512024,
     "status": "ok",
     "timestamp": 1634568193467,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "McQc1_xkBbVp",
    "outputId": "965c9de2-04f8-4530-e820-2a207e008eae",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch= 0 \t time= 49.26979398727417 \t lr= 0.001 \t exp(loss)= 276.40929708125935\n",
      "test: exp(loss) =  198.14782446824466\n",
      "\n",
      "epoch= 1 \t time= 100.38009977340698 \t lr= 0.001 \t exp(loss)= 148.85428102508214\n",
      "test: exp(loss) =  168.56028629306493\n",
      "\n",
      "epoch= 2 \t time= 151.7474946975708 \t lr= 0.0009090909090909091 \t exp(loss)= 112.01972940235004\n",
      "test: exp(loss) =  159.53060590431687\n",
      "\n",
      "epoch= 3 \t time= 202.7228238582611 \t lr= 0.0008264462809917355 \t exp(loss)= 92.53003794418727\n",
      "test: exp(loss) =  158.29914484150208\n",
      "\n",
      "epoch= 4 \t time= 253.9203450679779 \t lr= 0.0007513148009015777 \t exp(loss)= 80.46591845356971\n",
      "test: exp(loss) =  159.69302774158947\n",
      "\n",
      "epoch= 5 \t time= 305.2703056335449 \t lr= 0.0006830134553650705 \t exp(loss)= 72.19765247455692\n",
      "test: exp(loss) =  162.3745335948197\n",
      "\n",
      "epoch= 6 \t time= 356.46911120414734 \t lr= 0.0006209213230591549 \t exp(loss)= 66.11349120495728\n",
      "test: exp(loss) =  165.57647032396972\n",
      "\n",
      "epoch= 7 \t time= 407.6614124774933 \t lr= 0.0005644739300537772 \t exp(loss)= 61.41710343891095\n",
      "test: exp(loss) =  168.68014507448387\n",
      "\n",
      "epoch= 8 \t time= 458.71091055870056 \t lr= 0.0005131581182307065 \t exp(loss)= 57.69185100837776\n",
      "test: exp(loss) =  171.35996452942464\n",
      "\n",
      "epoch= 9 \t time= 510.2434732913971 \t lr= 0.0004665073802097331 \t exp(loss)= 54.642704136686405\n",
      "test: exp(loss) =  174.4089373575201\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start=time.time()\n",
    "for epoch in range(10):\n",
    "\n",
    "    # divide the learning rate by 3 except after the first epoch\n",
    "    if epoch >= 2:\n",
    "        optimizer.param_groups[0]['lr'] /= 1.1 \n",
    "        my_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # set the running quantities to zero at the beginning of the epoch\n",
    "    running_loss=0\n",
    "    num_batches=0    \n",
    "    for count in range( 0 , 46478-seq_length ,  seq_length//2):\n",
    "        \n",
    "        # Set the gradients to zeros\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # create a minibatch and the positional encoding\n",
    "        minibatch_data = train_data[ count   : count+seq_length   ]\n",
    "        minibatch_label = train_data[ count+1 : count+seq_length+1 ]    \n",
    "        pos = generate_positional_encoding(seq_length, hidden_size) # size=(seq_length, hidden_dim) \n",
    "        \n",
    "        # send them to the gpu\n",
    "        minibatch_data = minibatch_data.to(device)\n",
    "        minibatch_label = minibatch_label.to(device)\n",
    "        pos = pos.to(device)\n",
    "        \n",
    "        # forward the minibatch through the net        \n",
    "        scores = net( minibatch_data, pos ) # size=(seq_length, bs, vocab_size)\n",
    "\n",
    "        # select the predicted words that used a window of attention of seq_length//2\n",
    "        scores = scores[-seq_length//2:,:,:]\n",
    "        minibatch_label = minibatch_label[-seq_length//2:,:]\n",
    "        \n",
    "        # reshape the scores and labels to huge batch of size bs*seq_length\n",
    "        scores = scores.view(  bs*seq_length//2 , vocab_size) # size=(seq_length/2.bs, vocab_size)\n",
    "        minibatch_label = minibatch_label.view(  bs*seq_length//2 ) # size=(seq_length/2.bs, vocab_size)\n",
    "       \n",
    "        # Compute the average of the losses of the data points in this huge batch\n",
    "        loss = criterion(scores, minibatch_label)\n",
    "        \n",
    "        # backward pass to compute dL/dR, dL/dV and dL/dW\n",
    "        loss.backward()\n",
    "\n",
    "        # do one step of stochastic gradient descent: R=R-lr(dL/dR), V=V-lr(dL/dV), ...\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update the running loss  \n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "    # compute stats for the full training set\n",
    "    total_loss = running_loss/num_batches\n",
    "    elapsed = time.time()-start\n",
    "    \n",
    "    print('')\n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'\\t lr=', my_lr, '\\t exp(loss)=',  math.exp(total_loss))\n",
    "    eval_on_test_set() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1634568193467,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "VWXXTLvwVaDc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "JRu41IdwBbVt"
   },
   "source": [
    "### Choose one sentence (taken from the test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 493,
     "status": "ok",
     "timestamp": 1634568349512,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "gSmC_QyMBbVt"
   },
   "outputs": [],
   "source": [
    "sentence1 = \"some analysts expect oil prices to remain relatively\"\n",
    "\n",
    "sentence2 = \"over the next days and weeks they say investors should look for stocks to\"\n",
    "\n",
    "sentence3 = \"prices averaging roughly $ N a barrel higher in the third\"\n",
    "\n",
    "sentence4 = \"i think my line has been very consistent mrs. hills said at a news\"\n",
    "\n",
    "sentence5 = \"this appears particularly true at gm which had strong sales in\"\n",
    "\n",
    "# or make your own sentence.  No capital letter or punctuation allowed. Each word must be in the allowed vocabulary.\n",
    "sentence6= \"he was very\"\n",
    "\n",
    "# SELECT THE SENTENCE HERE\n",
    "mysentence = sentence1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoC9H2zBBbVu"
   },
   "source": [
    "### Convert the sentence into a vector, then send to GPU, and display the the network prediction for the next wordÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1634568352272,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "YenIJTXcBbVu",
    "outputId": "7762d1de-e6e2-4ea6-c914-78ab474e106d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some analysts expect oil prices to remain relatively ... \n",
      "\n",
      "20.5%\t flat\n",
      "10.2%\t strong\n",
      "7.7%\t narrow\n",
      "3.5%\t <unk>\n",
      "3.2%\t healthy\n",
      "3.0%\t sluggish\n",
      "2.6%\t quiet\n",
      "2.0%\t genetic\n",
      "1.7%\t fixed\n",
      "1.4%\t revised\n",
      "1.3%\t profit\n",
      "1.3%\t soft\n",
      "1.3%\t active\n",
      "1.3%\t high\n",
      "1.2%\t positive\n",
      "1.1%\t stable\n",
      "1.0%\t big\n",
      "1.0%\t car\n",
      "1.0%\t bad\n",
      "0.9%\t close\n",
      "0.8%\t heavy\n",
      "0.7%\t cautious\n",
      "0.7%\t brisk\n",
      "0.6%\t poor\n",
      "0.6%\t increasingly\n",
      "0.5%\t short\n",
      "0.5%\t low\n",
      "0.5%\t full\n",
      "0.5%\t late\n",
      "0.5%\t thin\n"
     ]
    }
   ],
   "source": [
    "minibatch_data = utils.sentence2vector(mysentence)\n",
    "minibatch_data = torch.cat((minibatch_data, minibatch_data), dim=0) # copy-paste the test sequence to use the same attention window size for each word\n",
    "pos = generate_positional_encoding(minibatch_data.size(0), hidden_size) \n",
    "\n",
    "minibatch_data = minibatch_data.to(device)\n",
    "pos = pos.to(device)   \n",
    "\n",
    "net.eval()\n",
    "scores = net( minibatch_data, pos )\n",
    "scores = scores[-1,:] # select the last score vector for the prediction of the next word from the input sequence\n",
    "\n",
    "print(mysentence, '... \\n')\n",
    "utils.show_next_word(scores.unsqueeze(0).unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1634568352273,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "-g3t66JccXCq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transformer_language_modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
