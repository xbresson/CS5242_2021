{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU0wD0LEBbVZ"
   },
   "source": [
    "# Lab 02: Sequence-To-Sequence with Transformers - Demo\n",
    "\n",
    "### The task is to learn to memorize an input  sequence of length 100 and output the same sequence of length 100 but shifted by one word in the future.\n",
    "For example, the input sequence is \"some analysts expect oil prices to remain relatively\"<br>\n",
    "and the output sequence is \"analysts expect oil prices to remain relatively high\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1634566698702,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "qoogmpRzBbVg",
    "outputId": "5d1cf4ca-264b-4d9d-da9b-5cb4f49ad097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "/content/gdrive/My Drive/CS5242_notebooks/labs_lecture12/lab02_translation/\n",
      "/content/gdrive/My Drive/CS5242_notebooks/labs_lecture12/lab02_translation\n"
     ]
    }
   ],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    # find automatically the path of the folder containing \"file_name\" :\n",
    "    file_name = 'transformer_translation.ipynb'\n",
    "    import subprocess\n",
    "    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n",
    "    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n",
    "    # if previous search failed or too long, comment the previous line and simply write down manually the path below :\n",
    "    #path_to_file = '/content/gdrive/My Drive/CS5242_2021_codes/codes/labs_lecture12/lab02_translation/'\n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"file_name\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1634566699273,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "A3yiLJBBBbVh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import time\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pe01LtUIBbVj"
   },
   "source": [
    "### GPU\n",
    "\n",
    "It is recommended to run this code on GPU:<br> \n",
    "* Time for 1 epoch on GPU : 1.5 sec w/ Google Colab Tesla P100-PCIE-16GB <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1634566699274,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "g_A4HBT3BbVj",
    "outputId": "780cb794-c757-4952-828b-31fd84392780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device= torch.device(\"cuda\")\n",
    "#device= torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda available with GPU:',torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6S3W2p84BbVk"
   },
   "source": [
    "### Download Penn Tree Bank\n",
    "\n",
    "The tensor train_data consists of 20 columns of 46,479 words.<br>\n",
    "The tensor test_data consists of 20 columns of 4,121 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1634566699274,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "TnE-JNp_BbVk",
    "outputId": "a59a9495-c958-4d68-e082-ffacb35f6a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46479, 20])\n",
      "torch.Size([4121, 20])\n"
     ]
    }
   ],
   "source": [
    "from utils import check_ptb_dataset_exists\n",
    "data_path=check_ptb_dataset_exists()\n",
    "\n",
    "train_data  =  torch.load(data_path+'ptb/train_data.pt')\n",
    "test_data   =  torch.load(data_path+'ptb/test_data.pt')\n",
    "\n",
    "print(  train_data.size()  )\n",
    "print(  test_data.size()   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKCi4xmTvbtK"
   },
   "source": [
    "### Extract a small part of PTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1634566699275,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "029kngXZ6aCp",
    "outputId": "d94273e8-5134-4f99-b0c4-17359fb6389d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([501, 20])\n"
     ]
    }
   ],
   "source": [
    "doc_len = 501\n",
    "train_data = train_data[:doc_len,:]\n",
    "print(  train_data.size()  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDxTJimKBbVl"
   },
   "source": [
    "### Some constants associated with the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1634566699275,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "MS9EUUvbBbVm"
   },
   "outputs": [],
   "source": [
    "bs = 20\n",
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U9UvE28BbVm"
   },
   "source": [
    "### Make an attention net class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1634566699276,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "RRmg_OUaBbVn"
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_positional_encoding(seq_length, dim):\n",
    "    assert dim == 2* (dim//2) # check if dim is divisible by 2\n",
    "    pe = torch.zeros(seq_length, dim)\n",
    "    position = torch.arange(0, seq_length, dtype=torch.float).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / dim))\n",
    "    pe[:,0::2] = torch.sin(position * div_term)\n",
    "    pe[:,1::2] = torch.cos(position * div_term)\n",
    "    return pe        \n",
    "        \n",
    "    \n",
    "class Transformer_decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, nb_heads):\n",
    "        super(Transformer_decoder, self).__init__()\n",
    "        assert hidden_size == nb_heads* (hidden_size//nb_heads) # check if hidden_size is divisible by nb_heads\n",
    "        self.MHA_selfatt = nn.MultiheadAttention(hidden_size, nb_heads)\n",
    "        self.MHA = nn.MultiheadAttention(hidden_size, nb_heads)\n",
    "        self.LLcat = nn.Linear(2*hidden_size, hidden_size)\n",
    "        self.LL1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.LL2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.LN1 = nn.LayerNorm(hidden_size)\n",
    "        self.LN2 = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "    def forward(self, g_seq , pos, h_enc_seq):  \n",
    "        seq_length = g_seq.size(0)\n",
    "        bs = g_seq.size(1)\n",
    "        pos = pos.unsqueeze(dim=1).repeat_interleave(bs,dim=1) # size=(seq_length, bs, hidden_dim) \n",
    "        h_cat = self.LLcat(torch.cat( (g_seq, pos), dim=2 )) # size=(seq_length, bs, hidden_dim) \n",
    "        mask_visited_nodes = torch.ones(1, seq_length, device=g_seq.device).bool() # True=no_attention # size=(1, seq_length) \n",
    "        h_seq = []\n",
    "        h_MHA_seq = []\n",
    "        for t in range(seq_length): \n",
    "            # prepare masks of attention\n",
    "            mask_visited_nodes = mask_visited_nodes.clone()\n",
    "            mask_visited_nodes[0,t] = False # allow attention to current word indexed by t\n",
    "            mask_visited_nodes_selfatt = mask_visited_nodes.clone()\n",
    "            mask_visited_nodes_selfatt = mask_visited_nodes_selfatt.repeat_interleave(seq_length,dim=0)\n",
    "            # MHA for masked self-attention \n",
    "            h_MHA_selfatt, _ = self.MHA_selfatt(h_cat, h_cat, h_cat, attn_mask=mask_visited_nodes_selfatt) # size=(1, bs, hidden_dim)\n",
    "            h_selfatt = self.LN1( h_cat + h_MHA_selfatt ) # size=(1, bs, hidden_dim)\n",
    "            # MHA for cross-attention layer\n",
    "            query = h_selfatt[t].unsqueeze(0) # size=(1, bs, hidden_dim) \n",
    "            h_MHA, _ = self.MHA(query, h_enc_seq, h_enc_seq, attn_mask=mask_visited_nodes) # size=(1, bs, hidden_dim)\n",
    "            h_MHA_seq.append(h_MHA)\n",
    "            h_seq.append(query)\n",
    "            \n",
    "        # cross-attention layer\n",
    "        h_MHA_seq = torch.stack(h_MHA_seq).squeeze() # size=(seq_length, bs, hidden_dim)  \n",
    "        h_seq = torch.stack(h_seq).squeeze() # size=(seq_length, bs, hidden_dim)  \n",
    "        h = self.LN1( h_seq + h_MHA_seq ) # size=(1, bs, hidden_dim)\n",
    "        h_MLP = self.LL2(torch.relu(self.LL1(h))) # size=(1, bs, hidden_dim) \n",
    "        h_seq = self.LN2( h + h_MLP ) # size=(1, bs, hidden_dim)   \n",
    "        return h_seq\n",
    "    \n",
    "\n",
    "class Transformer_encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, nb_heads):\n",
    "        super(Transformer_encoder, self).__init__()\n",
    "        assert hidden_size == nb_heads* (hidden_size//nb_heads) # check if hidden_size is divisible by nb_heads\n",
    "        self.MHA = nn.MultiheadAttention(hidden_size, nb_heads)\n",
    "        self.LLcat = nn.Linear(2*hidden_size, hidden_size)\n",
    "        self.LL1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.LL2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.LN1 = nn.LayerNorm(hidden_size)\n",
    "        self.LN2 = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "    def forward(self, g_seq , pos):  \n",
    "        seq_length = g_seq.size(0)\n",
    "        bs = g_seq.size(1)\n",
    "        pos = pos.unsqueeze(dim=1).repeat_interleave(bs,dim=1) # size=(seq_length, bs, hidden_dim) \n",
    "        h_cat = self.LLcat(torch.cat( (g_seq, pos), dim=2 )) # size=(seq_length, bs, hidden_dim) \n",
    "        h_MHA_seq, _ = self.MHA(h_cat, h_cat, h_cat) # size=(seq_length, bs, hidden_dim)\n",
    "        h = self.LN1( h_cat + h_MHA_seq ) # size=(1, bs, hidden_dim) 2\n",
    "        h_MLP = self.LL2(torch.relu(self.LL1(h))) # size=(1, bs, hidden_dim) \n",
    "        h_seq = self.LN2( h + h_MLP ) # size=(1, bs, hidden_dim) \n",
    "        return h_seq\n",
    "    \n",
    "    \n",
    "class ANN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, nb_heads):\n",
    "        super(ANN, self).__init__()\n",
    "        self.encoder = Transformer_encoder(hidden_size, nb_heads)\n",
    "        self.decoder = Transformer_decoder(hidden_size, nb_heads)\n",
    "    \n",
    "    def forward(self, g_seq , pos ):\n",
    "        h_enc_seq = self.encoder( g_seq , pos ) # size=(seq_length, bs, hidden_dim) \n",
    "        h_dec_seq = self.decoder( g_seq , pos, h_enc_seq ) # size=(seq_length, bs, hidden_dim) \n",
    "        return h_dec_seq \n",
    "    \n",
    "\n",
    "class attention_net(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, nb_heads):\n",
    "        super(attention_net, self).__init__()  \n",
    "        self.layer1 = nn.Embedding( vocab_size  , hidden_size  )\n",
    "        self.layer2 = ANN(hidden_size, nb_heads)\n",
    "        self.layer3 = nn.Linear(    hidden_size , vocab_size   )\n",
    "\n",
    "    def forward(self, word_seq, pos ):\n",
    "        g_seq     =   self.layer1( word_seq ) # size=(seq_length, bs, hidden_dim) \n",
    "        h_seq     =   self.layer2( g_seq , pos ) # size=(seq_length, bs, hidden_dim) \n",
    "        score_seq =   self.layer3( h_seq ) # size=(seq_length, bs, vocab_size)\n",
    "        return score_seq \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gnTKxy9BbVr"
   },
   "source": [
    "### Build the net. Choose the hidden size to be 128 and the number of heads to be 16. \n",
    "### How many parameters in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1634566910385,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "zj7UdAZqrP1R",
    "outputId": "f57165f9-f358-486f-8fc3-b0f06555452d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_net(\n",
      "  (layer1): Embedding(10000, 128)\n",
      "  (layer2): ANN(\n",
      "    (encoder): Transformer_encoder(\n",
      "      (MHA): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (LLcat): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (LL1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (LL2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (LN1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (LN2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): Transformer_decoder(\n",
      "      (MHA_selfatt): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (MHA): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (LLcat): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (LL1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (LL2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (LN1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (LN2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Linear(in_features=128, out_features=10000, bias=True)\n",
      ")\n",
      "There are 2901008 (2.90 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128 \n",
    "nb_heads = 16\n",
    "\n",
    "net = attention_net(hidden_size, nb_heads)\n",
    "print(net)\n",
    "utils.display_num_param(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khaDFxmwBbVr"
   },
   "source": [
    "### Send the weights of the networks to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1634566910938,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "3XX6XNnArP1S"
   },
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eecX1xVaBbVs"
   },
   "source": [
    "### Choose the loss to be the cross-entropy and the optimizer to be Adam, as well as the hyperparameters: \n",
    "* initial learning rate = 0.001\n",
    "* sequence length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1634566911994,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "8mRAllGrrP1S"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "my_lr = 0.001\n",
    "seq_length = 100\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=my_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frtpNDBLBbVs"
   },
   "source": [
    "### Do 50 passes through the training set\n",
    "### Observe the train perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61136,
     "status": "ok",
     "timestamp": 1634566974730,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "McQc1_xkBbVp",
    "outputId": "71cafe76-e1ff-4951-87b0-7962fd3e2c9c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 \t time= 1.2681910991668701 \t lr= 0.001 \t exp(loss)= 6883.244457877534\n",
      "epoch= 10 \t time= 13.575231075286865 \t lr= 0.001 \t exp(loss)= 260.02380432357336\n",
      "epoch= 20 \t time= 25.824889659881592 \t lr= 0.001 \t exp(loss)= 77.53207331566317\n",
      "epoch= 30 \t time= 37.98508954048157 \t lr= 0.001 \t exp(loss)= 23.98241062630039\n",
      "epoch= 40 \t time= 50.14222478866577 \t lr= 0.001 \t exp(loss)= 6.672884276588563\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "for epoch in range(50):\n",
    "    \n",
    "    # set the running quantities to zero at the beginning of the epoch\n",
    "    running_loss=0\n",
    "    num_batches=0    \n",
    "    doc_len = train_data.size(0)\n",
    "    for count in range( 0 , doc_len-seq_length ,  seq_length): \n",
    "        \n",
    "        # Set the gradients to zeros\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # create a minibatch\n",
    "        minibatch_data = train_data[ count   : count+seq_length   ]\n",
    "        minibatch_label = train_data[ count+1 : count+seq_length+1 ]    \n",
    "        pos = generate_positional_encoding(seq_length, hidden_size) # size=(seq_length, hidden_dim) \n",
    "        \n",
    "        # send them to the gpu\n",
    "        minibatch_data = minibatch_data.to(device)\n",
    "        minibatch_label = minibatch_label.to(device)\n",
    "        pos = pos.to(device)\n",
    "        \n",
    "        # forward the minibatch through the net        \n",
    "        scores = net( minibatch_data, pos ) # size=(seq_length, bs, vocab_size)\n",
    "\n",
    "        # reshape the scores and labels to huge batch of size bs*seq_length\n",
    "        scores = scores.view(  bs*seq_length , vocab_size) # size=(seq_length.bs, vocab_size)\n",
    "        minibatch_label = minibatch_label.view(  bs*seq_length ) # size=(seq_length.bs, vocab_size)\n",
    "       \n",
    "        # Compute the average of the losses of the data points in this huge batch\n",
    "        loss = criterion(scores, minibatch_label)\n",
    "        \n",
    "        # backward pass to compute dL/dR, dL/dV and dL/dW\n",
    "        loss.backward()\n",
    "\n",
    "        # do one step of stochastic gradient descent: R=R-lr(dL/dR), V=V-lr(dL/dV), ...\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update the running loss  \n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "    # compute stats for the full training set\n",
    "    total_loss = running_loss/num_batches\n",
    "    elapsed = time.time()-start\n",
    "    \n",
    "    if not epoch%10:\n",
    "      print('epoch=',epoch, '\\t time=', elapsed,'\\t lr=', my_lr, '\\t exp(loss)=',  math.exp(total_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1634566736662,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "S8C3CXylrP1T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRt3XQhgrP1T"
   },
   "source": [
    "### Check if the network was successful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 449,
     "status": "ok",
     "timestamp": 1634567074104,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "49t0myXb6aCy",
    "outputId": "7946e636-dad9-410e-ea89-241124343edc",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence: tensor([  93,  718,  590, 1569,   35, 4979,   95,   87,  507,   93,   78,  718,\n",
      "          26, 2966,  467,   35, 4979,  119, 2862,   64, 1177, 2640,  861, 1449,\n",
      "          26,  956, 5130,   98,   24,   32, 2361,   34,   78,   54,  461,  229,\n",
      "          32,  523,  823, 1328,   48, 2749, 1977,  718,  746,   32, 2749,  798,\n",
      "          95,   64,   27,  363,   64,  926,  138,  924,   42,   27,   27,  467,\n",
      "          79,   42,   32,  935,  108,  128, 4955,   24,   32,  798,  718,  220,\n",
      "         971,   64,  660,   32, 1515,  531,   32,  462,   40,  124,   64, 2273,\n",
      "        4586,   35, 4979,  590,   93, 2966,  718,  220,   26,  109, 2862,   64,\n",
      "        1177,  718,  220,  709])\n",
      "Expected output sequence: tensor([ 718,  590, 1569,   35, 4979,   95,   87,  507,   93,   78,  718,   26,\n",
      "        2966,  467,   35, 4979,  119, 2862,   64, 1177, 2640,  861, 1449,   26,\n",
      "         956, 5130,   98,   24,   32, 2361,   34,   78,   54,  461,  229,   32,\n",
      "         523,  823, 1328,   48, 2749, 1977,  718,  746,   32, 2749,  798,   95,\n",
      "          64,   27,  363,   64,  926,  138,  924,   42,   27,   27,  467,   79,\n",
      "          42,   32,  935,  108,  128, 4955,   24,   32,  798,  718,  220,  971,\n",
      "          64,  660,   32, 1515,  531,   32,  462,   40,  124,   64, 2273, 4586,\n",
      "          35, 4979,  590,   93, 2966,  718,  220,   26,  109, 2862,   64, 1177,\n",
      "         718,  220,  709, 5131])\n",
      "Predicted output sequence: tensor([ 718,  590, 1569,   35, 4979,   95,   87,  507,  108,   78,  718,   26,\n",
      "        2966,  467,   35, 4979,   30, 2862,   64, 1177, 2640,  861, 1449,   26,\n",
      "         956, 5130,   98,   24,   32, 2361,   34,   35,  718,  461,  229,   32,\n",
      "         523,  461, 1328,   48, 2749, 1977,  718,  220,   35, 2749,  798,   64,\n",
      "          64,   27,   27,   64,   27,  138,  924,   42,   27,   27,   27,   79,\n",
      "          80,   32,  935,  108,   32, 4955,   24,   32,  798,   64,  220,  971,\n",
      "          64,  660,   32, 1515,   46,   32,  462,   40,  124,   64, 2273, 4586,\n",
      "          35, 4979,  590,   93,  718,  718,  220,   35,   32, 2862,   64, 1177,\n",
      "         718,  220,  709, 5131], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "minibatch_data = train_data[ 0:0+seq_length, 1   ].unsqueeze(1)\n",
    "minibatch_label = train_data[ 0+1:0+seq_length+1, 1].unsqueeze(1)\n",
    "print('Input sequence:', minibatch_data[:,0])\n",
    "print('Expected output sequence:', minibatch_label[:,0])\n",
    "pos = generate_positional_encoding(seq_length, hidden_size) # size=(seq_length, hidden_dim) \n",
    "             \n",
    "minibatch_data = minibatch_data.to(device)\n",
    "minibatch_label = minibatch_label.to(device)\n",
    "pos = pos.to(device)\n",
    "\n",
    "scores = net( minibatch_data, pos ) \n",
    "seq = scores.argmax(dim=1)\n",
    "print('Predicted output sequence:', seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1634566736663,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "VWXXTLvwVaDc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1634566736664,
     "user": {
      "displayName": "Xavier Bresson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgioGx5OdvAc1VASSVcYQ8NHiQo4PQ7B39ZSmys=s64",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "HxNkId08BbVv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transformer_translation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
